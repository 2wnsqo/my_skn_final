from openai import OpenAI
import os
import json
from dotenv import load_dotenv
from typing import List, Dict
import time
import re

load_dotenv()

# ê°œë³„ í‰ê°€ìš© LLM í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
client = OpenAI()  # ìë™ìœ¼ë¡œ .envì˜ OPENAI_API_KEY ì‚¬ìš©ë¨

# ê°œë³„ í‰ê°€ìš© ëª¨ë¸ ì„¤ì • (ì—¬ê¸°ì„œ ëª¨ë¸ ë³€ê²½ ê°€ëŠ¥)
INDIVIDUAL_EVAL_MODEL = "gpt-4o"  # ë˜ëŠ” "gpt-4", "gpt-3.5-turbo" ë“±

# ë°˜ë§ ê°ì§€ë¥¼ ìœ„í•œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
def detect_casual_speech(text: str) -> bool:
    """
    ë°˜ë§ ì‚¬ìš© ì—¬ë¶€ë¥¼ ê°ì§€í•˜ëŠ” í•¨ìˆ˜
    ì¸ìš©ë¬¸ì´ë‚˜ ì˜ˆì‹œ ì„¤ëª…ì€ ì œì™¸í•˜ê³  ì‹¤ì œ ë©´ì ‘ ë‹µë³€ì—ì„œì˜ ë°˜ë§ë§Œ ê°ì§€
    """
    # ì¸ìš©ë¬¸ íŒ¨í„´ (ë”°ì˜´í‘œ ì•ˆì˜ ë‚´ìš© ì œì™¸)
    quote_patterns = [
        r'"[^"]*"',  # í°ë”°ì˜´í‘œ
        r"'[^']*'",  # ì‘ì€ë”°ì˜´í‘œ
        r'"[^"]*"',  # ì „ê° í°ë”°ì˜´í‘œ
        r"'[^']*'",  # ì „ê° ì‘ì€ë”°ì˜´í‘œ
    ]
    
    # ì¸ìš©ë¬¸ ì œê±°
    cleaned_text = text
    for pattern in quote_patterns:
        cleaned_text = re.sub(pattern, '', cleaned_text)
    
    # ë°˜ë§ íŒ¨í„´ë“¤
    casual_patterns = [
        r'\bë‚˜ëŠ”\b',      # "ë‚˜ëŠ”"
        r'\bí–ˆì–´\b',      # "í–ˆì–´"
        r'\bìˆì–´\b',      # "ìˆì–´" 
        r'\bì´ì•¼\b',      # "ì´ì•¼"
        r'\bí–ˆì§€\b',      # "í–ˆì§€"
        r'[ê°€-í£]+í•´\.?$',  # ë¬¸ì¥ ë "~í•´"
        r'[ê°€-í£]+ì•¼\.?$',  # ë¬¸ì¥ ë "~ì•¼"
        r'[ê°€-í£]+ì§€\.?$',  # ë¬¸ì¥ ë "~ì§€"
        r'[ê°€-í£]+ì–´\.?$',  # ë¬¸ì¥ ë "~ì–´"
        r'[ê°€-í£]+ë‹¤\.?$',  # ë¬¸ì¥ ë "~ë‹¤" (ë‹¨, ì¡´ëŒ“ë§ ì œì™¸)
    ]
    
    # ì¡´ëŒ“ë§ ì˜ˆì™¸ íŒ¨í„´ (ë°˜ë§ë¡œ ì˜¤ì¸ë  ìˆ˜ ìˆëŠ” ì¡´ëŒ“ë§ë“¤)
    polite_exceptions = [
        r'ìŠµë‹ˆë‹¤\.?$',    # "~ìŠµë‹ˆë‹¤"
        r'í–ˆìŠµë‹ˆë‹¤\.?$',  # "~í–ˆìŠµë‹ˆë‹¤"
        r'ì…ë‹ˆë‹¤\.?$',    # "~ì…ë‹ˆë‹¤"
        r'ìˆìŠµë‹ˆë‹¤\.?$',  # "~ìˆìŠµë‹ˆë‹¤"
        r'í•©ë‹ˆë‹¤\.?$',    # "~í•©ë‹ˆë‹¤"
    ]
    
    # ê° ë¬¸ì¥ë³„ë¡œ í™•ì¸
    sentences = re.split(r'[.!?]', cleaned_text)
    
    for sentence in sentences:
        sentence = sentence.strip()
        if not sentence:
            continue
            
        # ì¡´ëŒ“ë§ ì˜ˆì™¸ í™•ì¸
        is_polite = any(re.search(pattern, sentence) for pattern in polite_exceptions)
        if is_polite:
            continue
            
        # ë°˜ë§ íŒ¨í„´ í™•ì¸
        has_casual = any(re.search(pattern, sentence) for pattern in casual_patterns)
        if has_casual:
            return True
    
    return False

# ğŸ¤– í”„ë¡¬í”„íŠ¸ ë¹Œë” (ì§ˆë¬¸ ì˜ë„ ìë™ ì¶”ì¶œ + í‰ê°€)
def build_prompt_with_intent_extraction(question, answer, company_info):
    # íšŒì‚¬ ì •ë³´ ë™ì  í¬ë§·íŒ… (ì‚°ì—…ë³„/íšŒì‚¬ë³„ íŠ¹í™”)
    company_name = company_info.get('name', 'íšŒì‚¬')
    
    # ì‚°ì—…ë³„ í‰ê°€ ê´€ì  ì„¤ì •
    industry_context = ""
    if 'IT' in company_name or 'tech' in company_info.get('tech_focus', []):
        industry_context = "IT/ê¸°ìˆ  ê¸°ì—…ì˜ ê´€ì ì—ì„œ ê¸°ìˆ ì  ì—­ëŸ‰ê³¼ ë¬¸ì œí•´ê²° ëŠ¥ë ¥ì„ ì¤‘ì ì ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”."
    elif 'ê¸ˆìœµ' in company_name or 'finance' in company_info.get('name', '').lower():
        industry_context = "ê¸ˆìœµì—…ì˜ ê´€ì ì—ì„œ ì‹ ë¢°ì„±, ì •í™•ì„±, ë¦¬ìŠ¤í¬ ê´€ë¦¬ ëŠ¥ë ¥ì„ ì¤‘ì ì ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”."
    else:
        industry_context = f"{company_name}ì˜ ì‚¬ì—… íŠ¹ì„±ê³¼ ê¸°ì—… ë¬¸í™”ë¥¼ ê³ ë ¤í•˜ì—¬ í‰ê°€í•˜ì„¸ìš”."
    
    company_section = f"""
ğŸ¢ íšŒì‚¬ ì •ë³´:
- íšŒì‚¬ëª…: {company_info['name']}
- ì¸ì¬ìƒ: {company_info.get('talent_profile', 'N/A')}
- í•µì‹¬ì—­ëŸ‰: {', '.join(company_info.get('core_competencies', []))}
- ê¸°ìˆ  ì¤‘ì : {', '.join(company_info.get('tech_focus', []))}
- ë©´ì ‘ í‚¤ì›Œë“œ: {', '.join(company_info.get('interview_keywords', []))}
- ì§ˆë¬¸ ë°©í–¥: {company_info.get('question_direction', 'N/A')}
- ê¸°ìˆ  ê³¼ì œ: {', '.join(company_info.get('technical_challenges', []))}

ğŸ“‹ ì¡°ì§ ë¬¸í™”:
- ê·¼ë¬´ ë°©ì‹: {company_info.get('company_culture', {}).get('work_style', 'N/A')}
- ì˜ì‚¬ê²°ì •: {company_info.get('company_culture', {}).get('decision_making', 'N/A')}
- ì„±ì¥ ì§€ì›: {company_info.get('company_culture', {}).get('growth_support', 'N/A')}
- í•µì‹¬ ê°€ì¹˜: {', '.join(company_info.get('company_culture', {}).get('core_values', []))}

ğŸ¯ í‰ê°€ ê´€ì : {industry_context}
"""
    # ì—­í• ë³„ ì •ë³´ (ì˜ˆì‹œ: ai_researcher, product_manager)
    roles = []
    for role_key in ['ai_researcher', 'product_manager']:
        if role_key in company_info:
            role = company_info[role_key]
            roles.append(f"- {role['name']} ({role['role']}): {role['experience']} / ì„±ê²©: {role['personality']} / í™”ë²•: {role['speaking_style']} / ì¤‘ì : {', '.join(role['focus_areas'])}")
    roles_section = '\n'.join(roles)
    if roles_section:
        company_section += f"\nì£¼ìš” ë©´ì ‘ê´€:\n{roles_section}"

    return f"""
ë‹¹ì‹ ì€ ì¸ê³µì§€ëŠ¥ ë©´ì ‘ê´€ì…ë‹ˆë‹¤. ë¨¼ì € ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ë¶„ì„í•œ í›„, íšŒì‚¬ ì •ë³´ì™€ ë©´ì ‘ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§€ì›ìì˜ ë‹µë³€ì„ í‰ê°€í•´ì£¼ì„¸ìš”.

**1ë‹¨ê³„: ì§ˆë¬¸ ì˜ë„ ë¶„ì„**
ì•„ë˜ ì§ˆë¬¸ë§Œì„ ë³´ê³  ë©´ì ‘ê´€ì´ ë¬´ì—‡ì„ ì•Œê³ ì í•˜ëŠ”ì§€ ì˜ë„ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”. (ë‹µë³€ì€ ë³´ì§€ ë§ê³  ì§ˆë¬¸ë§Œìœ¼ë¡œ íŒë‹¨)

[ì§ˆë¬¸]: {question}

**2ë‹¨ê³„: ë‹µë³€ í‰ê°€**
ì´ì œ ë‹µë³€ì„ ë³´ê³  ìœ„ì—ì„œ ë¶„ì„í•œ ì§ˆë¬¸ ì˜ë„ì— ë§ê²Œ í‰ê°€í•´ì£¼ì„¸ìš”.

ğŸ“ í‰ê°€ í•­ëª© ë° ê°€ì¤‘ì¹˜:
- ì§ˆë¬¸ ì˜ë„ ì¼ì¹˜ë„ (25ì ): ì§ˆë¬¸ì˜ í•µì‹¬ ì˜ë„ë¥¼ ì •í™•íˆ íŒŒì•…í•˜ê³  ì‘ë‹µí–ˆëŠ”ê°€? (ê°€ì¥ ì¤‘ìš”)
- ì¸ì¬ìƒ ì í•©ì„± (18ì ): íšŒì‚¬ ì¸ì¬ìƒê³¼ ì–´ëŠ ì •ë„ ë¶€í•©í•˜ëŠ”ê°€?
- ë…¼ë¦¬ì„± (12ì ): ì£¼ì¥ê³¼ ê·¼ê±°ê°€ ë…¼ë¦¬ì ìœ¼ë¡œ ì—°ê²°ë˜ì—ˆëŠ”ê°€?
- íƒ€ë‹¹ì„± (12ì ): ì œì‹œëœ ê²½í—˜ì´ ì‹ ë¢° ê°€ëŠ¥í•˜ê³  ê³¼ì¥ë˜ì§€ ì•Šì•˜ëŠ”ê°€?
- í‚¤ì›Œë“œ ì í•©ì„± (10ì ): ë©´ì ‘ í‚¤ì›Œë“œë‚˜ ì§ˆë¬¸ ë°©í–¥ê³¼ ì–¼ë§ˆë‚˜ ê´€ë ¨ ìˆëŠ”ê°€?
- ì˜ˆì˜/ë§¤ë„ˆ (23ì ): ë©´ì ‘ ìƒí™©ì— ì ì ˆí•œ ì¡´ëŒ“ë§ê³¼ ì˜ˆì˜ë¥¼ ê°–ì¶”ì—ˆëŠ”ê°€?

ğŸ’¡ ì°¸ê³ : ì´ ë‹µë³€ì€ ë³„ë„ ML ëª¨ë¸ì—ì„œë„ í‰ê°€ë˜ë©°, ML ì ìˆ˜ëŠ” ë³´í†µ 10~50ì  ë²”ìœ„ë¡œ ì‚°ì¶œë©ë‹ˆë‹¤.

ğŸš¨ ì ˆëŒ€ ê·œì¹™: ë©´ì ‘ì—ì„œ ë°˜ë§ì´ë‚˜ ë¬´ë¡€í•œ í‘œí˜„ì„ ì‚¬ìš©í•œ ê²½ìš° ë¬´ì¡°ê±´ 50ì ì„ ì°¨ê°í•©ë‹ˆë‹¤.
- ë°˜ë§ íŒ¨í„´: ë¬¸ì¥ ëì˜ "~í•´", "~ì•¼", "~ì§€", "~ì–´", "~ë‹¤", "ë‚˜ëŠ”", "í–ˆì–´", "ìˆì–´", "ì´ì•¼", "í–ˆì§€" ë“±
- ë‹¨, ì¸ìš©ë¬¸ì´ë‚˜ ì˜ˆì‹œ ì„¤ëª… ì¤‘ì˜ ë°˜ë§ì€ ì œì™¸ ("ê·¸ë•Œ ìƒì‚¬ê°€ 'ê´œì°®ë‹¤'ê³  í–ˆìŠµë‹ˆë‹¤" ë“±)
- ì´ëŠ” í˜‘ìƒ ë¶ˆê°€ëŠ¥í•œ ì ˆëŒ€ ê·œì¹™ì´ë©°, ë‚´ìš©ì´ ì•„ë¬´ë¦¬ ì¢‹ì•„ë„ ë°˜ë“œì‹œ ì ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
- ì˜ˆì˜/ë§¤ë„ˆ ì ìˆ˜ë„ 0~5ì  ì´í•˜ë¡œë§Œ í‰ê°€í•˜ì„¸ìš”.

--- íšŒì‚¬ ì •ë³´ ---
{company_section}

--- ì§€ì›ì ë‹µë³€ ---
[ë‹µë³€]: {answer}

--- ì¶œë ¥ í˜•ì‹ ---
**ì§ˆë¬¸ ì˜ë„ ë¶„ì„**: [ì´ ì§ˆë¬¸ì„ í†µí•´ ë©´ì ‘ê´€ì´ ì•Œê³ ì í•˜ëŠ” ê²ƒ]

**ë‹µë³€ í‰ê°€ ê²°ê³¼**:
ì˜ë„ ì¼ì¹˜ë„ ì ìˆ˜ (25ì  ë§Œì ): Xì  - ì´ìœ : [...]
ì¸ì¬ìƒ ì í•©ì„± ì ìˆ˜ (18ì  ë§Œì ): Xì  - ì´ìœ : [...]
ë…¼ë¦¬ì„± ì ìˆ˜ (12ì  ë§Œì ): Xì  - ì´ìœ : [...]
íƒ€ë‹¹ì„± ì ìˆ˜ (12ì  ë§Œì ): Xì  - ì´ìœ : [...]
í‚¤ì›Œë“œ ì í•©ì„± ì ìˆ˜ (10ì  ë§Œì ): Xì  - ì´ìœ : [...]
ì˜ˆì˜/ë§¤ë„ˆ ì ìˆ˜ (23ì  ë§Œì ): Xì  - ì´ìœ : [...]

ê¸°ë³¸ ì´ì : XXì 
ì˜ˆì˜ í˜ë„í‹°: -Xì  (ì˜ˆì˜ê°€ ë¶€ì¡±í•œ ê²½ìš° -50ì , ì—†ìœ¼ë©´ -0ì )
ìµœì¢… ì´ì : XXì  (ìµœì†Œ 0ì )

[ğŸ’¡ ì „ì²´ í”¼ë“œë°±]
- ğŸ‘ ì¢‹ì•˜ë˜ ì : ...
- ğŸ‘ ì•„ì‰¬ìš´ ì : ...
- âœ¨ ê°œì„  ì œì•ˆ: ...
- ì´í‰: ...
"""

# GPT í˜¸ì¶œ í•¨ìˆ˜
def evaluate_with_gpt(prompt: str) -> str:
    """
    ê°œë³„ í‰ê°€ìš© LLM í˜¸ì¶œ í•¨ìˆ˜
    
    Args:
        prompt (str): í‰ê°€ìš© í”„ë¡¬í”„íŠ¸
        
    Returns:
        str: LLM ì‘ë‹µ ê²°ê³¼
    """
    try:
        response = client.chat.completions.create(
            model=INDIVIDUAL_EVAL_MODEL,  # ê°œë³„ í‰ê°€ ì „ìš© ëª¨ë¸ ì‚¬ìš©
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ë§¤ìš° ì—„ê²©í•œ ë©´ì ‘ê´€ì…ë‹ˆë‹¤. ë°˜ë§ ì‚¬ìš© ì‹œ ë°˜ë“œì‹œ 50ì ì„ ì°¨ê°í•˜ê³ , ì¶œë ¥ í˜•ì‹ì„ ë°˜ë“œì‹œ ì§€í‚¤ì„¸ìš”. ì˜ˆì˜ì—†ëŠ” ë‹µë³€ì—ëŠ” ì ˆëŒ€ ê´€ëŒ€í•˜ì§€ ë§ˆì„¸ìš”."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"âš ï¸ ê°œë³„ í‰ê°€ LLM ({INDIVIDUAL_EVAL_MODEL}) í˜¸ì¶œ ì—ëŸ¬:", e)
        return "ERROR"

# ì „ì²´ í‰ê°€ ë£¨í”„ (company_infoë¥¼ ì¸ìë¡œ ë°›ìŒ)
def evaluate_all(interview_data: List[Dict[str, str]], company_info: dict) -> List[Dict[str, str]]:
    results = []
    for idx, item in enumerate(interview_data):
        print(f"ğŸ¤ ì§ˆë¬¸ {idx+1} í‰ê°€ ì¤‘...")
        prompt = build_prompt(item["question"], item["answer"], item["intent"], company_info)
        evaluation = evaluate_with_gpt(prompt)
        results.append({
            "ì§ˆë¬¸": item["question"],
            "ë‹µë³€": item["answer"],
            "ì˜ë„": item["intent"],
            "í‰ê°€ê²°ê³¼": evaluation
        })
        # time.sleep(1.2)
    return results

def evaluate_single_qa(question: str, answer: str, intent: str, company_info: dict) -> str:
    """ë‹¨ì¼ ì§ˆë¬¸-ë‹µë³€ ìŒì˜ LLM í‰ê°€ ìˆ˜í–‰ (êµ¬ ë²„ì „ - í˜¸í™˜ì„± ìœ ì§€)"""
    prompt = build_prompt(question, answer, intent, company_info)
    evaluation = evaluate_with_gpt(prompt)
    return evaluation

def evaluate_single_qa_with_intent_extraction(question: str, answer: str, company_info: dict) -> dict:
    """
    ì§ˆë¬¸ ì˜ë„ ìë™ ì¶”ì¶œ + ë‹¨ì¼ ì§ˆë¬¸-ë‹µë³€ ìŒì˜ LLM í‰ê°€ ìˆ˜í–‰
    
    Returns:
        dict: {"evaluation": str, "extracted_intent": str}
    """
    prompt = build_prompt_with_intent_extraction(question, answer, company_info)
    evaluation = evaluate_with_gpt(prompt)
    
    # ì‘ë‹µì—ì„œ ì§ˆë¬¸ ì˜ë„ ì¶”ì¶œ
    extracted_intent = ""
    if "**ì§ˆë¬¸ ì˜ë„ ë¶„ì„**:" in evaluation:
        intent_start = evaluation.find("**ì§ˆë¬¸ ì˜ë„ ë¶„ì„**:") + len("**ì§ˆë¬¸ ì˜ë„ ë¶„ì„**:")
        intent_end = evaluation.find("**ë‹µë³€ í‰ê°€ ê²°ê³¼**:")
        if intent_end != -1:
            extracted_intent = evaluation[intent_start:intent_end].strip()
        else:
            # ë‹¤ìŒ ì¤„ë°”ê¿ˆê¹Œì§€
            intent_end = evaluation.find("\n", intent_start)
            if intent_end != -1:
                extracted_intent = evaluation[intent_start:intent_end].strip()
    
    return {
        "evaluation": evaluation,
        "extracted_intent": extracted_intent
    }

# ë©”ì¸ ì²˜ë¦¬
if __name__ == "__main__":
    # ì…ë ¥ JSON íŒŒì¼ëª…
    input_file = "interview_data.json"
    output_file = "evaluation_results.json"
    company_file = "company_info.json"

    # ì…ë ¥ JSON ë¡œë”©
    with open(input_file, "r", encoding="utf-8") as f:
        interview_data = json.load(f)
    with open(company_file, "r", encoding="utf-8") as f:
        company_info = json.load(f)

    # í‰ê°€ ì‹¤í–‰
    results = evaluate_all(interview_data, company_info)

    # ì¶œë ¥ ì €ì¥
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ‰ í‰ê°€ ì™„ë£Œ! ê²°ê³¼ëŠ” '{output_file}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
